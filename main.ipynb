{
 "cells": [
  {
   "cell_type": "code",
   "id": "86e8582c6e5df2de",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-09T17:20:36.219352Z",
     "start_time": "2024-06-09T17:20:36.216713Z"
    }
   },
   "source": [
    "import os\n",
    "import uuid\n",
    "from typing import Sequence\n",
    "\n",
    "import torch\n",
    "from clickhouse_connect.driver import Client\n",
    "from pydub import AudioSegment\n",
    "import numpy as np\n",
    "import math\n",
    "import clickhouse_connect\n",
    "from loguru import logger\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2Model"
   ],
   "outputs": [],
   "execution_count": 188
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T16:49:39.884046Z",
     "start_time": "2024-06-09T16:49:39.879356Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def normalize(arr: np.array) -> np.array:\n",
    "    \"\"\"\n",
    "    Normalize a numpy array.\n",
    "\n",
    "    This function takes a numpy array and returns a normalized version of the array.\n",
    "    Normalization scales the array so that its norm (length) is 1, while maintaining the \n",
    "    direction of the vector.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    arr : np.array\n",
    "        The input numpy array to be normalized.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.array\n",
    "        The normalized numpy array. If the norm of the input array is 0, the original array \n",
    "        is returned unchanged.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> import numpy as np\n",
    "    >>> arr = np.array([1, 2, 3])\n",
    "    >>> normalize(arr)\n",
    "    array([0.26726124, 0.53452248, 0.80178373])\n",
    "    \n",
    "    >>> arr = np.array([0, 0, 0])\n",
    "    >>> normalize(arr)\n",
    "    array([0, 0, 0])\n",
    "    \"\"\"\n",
    "    norm = np.linalg.norm(arr)\n",
    "    if norm == 0:\n",
    "        return arr\n",
    "    return arr / norm"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 149
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T11:59:37.758555Z",
     "start_time": "2024-06-09T11:59:37.754332Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def split_on_chunk(path2mp3: str, chunk_size: int = 1024, sample_rate: int = 16000) -> AudioSegment:\n",
    "    \"\"\"\n",
    "    Splits an MP3 audio file into chunks of a specified size and returns them as a generator.\n",
    "\n",
    "    Args:\n",
    "        path2mp3 (str): The file path to the MP3 audio file.\n",
    "        chunk_size (int, optional): The size of each chunk in milliseconds. Defaults to 1024 ms.\n",
    "        sample_rate (int, optional): The sample rate to set for the audio in Hz. Defaults to 16000 Hz.\n",
    "\n",
    "    Yields:\n",
    "        AudioSegment: A chunk of the audio as an AudioSegment object.\n",
    "\n",
    "    Example:\n",
    "        for chunk in split_on_chunk(\"example.mp3\", chunk_size=5000, sample_rate=22050):\n",
    "            # Process each chunk\n",
    "            pass\n",
    "\n",
    "    Note:\n",
    "        - The audio is converted to mono and the specified sample rate before splitting.\n",
    "        - The last chunk may be shorter than the specified chunk size if the total length of the audio\n",
    "          is not a multiple of chunk_size.\n",
    "    \"\"\"\n",
    "    audio = AudioSegment.from_mp3(path2mp3)\n",
    "    audio = audio.set_frame_rate(sample_rate).set_channels(1)\n",
    "    \n",
    "    total_length = len(audio)\n",
    "    num_chunks = math.ceil(total_length / chunk_size)\n",
    "    \n",
    "    for i in range(num_chunks):\n",
    "        start_time = i * chunk_size\n",
    "        end_time = min((i + 1) * chunk_size, total_length)\n",
    "        chunk = audio[start_time:end_time]\n",
    "        yield chunk"
   ],
   "id": "343dfe40e3ff37bf",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T12:00:11.165965Z",
     "start_time": "2024-06-09T12:00:11.163494Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_embedding(chunk: AudioSegment, processor: Wav2Vec2Processor, model: Wav2Vec2Model) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Extracts an embedding from an audio chunk using a Wav2Vec2 model.\n",
    "\n",
    "    Args:\n",
    "        chunk (AudioSegment): The audio chunk to process, represented as an AudioSegment object.\n",
    "        processor (Wav2Vec2Processor): The Wav2Vec2 processor to preprocess the audio chunk.\n",
    "        model (Wav2Vec2Model): The pre-trained Wav2Vec2 model to generate the embedding.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: The embedding generated by the Wav2Vec2 model.\n",
    "\n",
    "    Example:\n",
    "        processor = Wav2Vec2Processor.from_pretrained('facebook/wav2vec2-base-960h')\n",
    "        model = Wav2Vec2Model.from_pretrained('facebook/wav2vec2-base-960h')\n",
    "        embedding = get_embedding(audio_chunk, processor, model)\n",
    "\n",
    "    Note:\n",
    "        - The audio chunk is converted to a numpy array of float32 samples.\n",
    "        - The processor converts the audio array to the appropriate input format for the model.\n",
    "        - The model's last hidden state is returned as the embedding.\n",
    "    \"\"\"\n",
    "    audio_array = np.array(chunk.get_array_of_samples(), dtype=np.float32)\n",
    "    audio_input = processor(audio_array, sampling_rate=chunk.frame_rate, return_tensors=\"pt\", padding=True).input_values\n",
    "    with torch.no_grad():    \n",
    "        embedding = model(audio_input).last_hidden_state\n",
    "    return embedding"
   ],
   "id": "81b9e4f0fe56cb9c",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T17:03:46.109332Z",
     "start_time": "2024-06-09T17:03:46.107172Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def save_embedding(embedding: np.array, title: str, client: Client) -> None:\n",
    "    \"\"\"\n",
    "    Saves an embedding to a database.\n",
    "\n",
    "    Args:\n",
    "        embedding (np.array): The embedding to save, represented as a NumPy array.\n",
    "        title (str): The title or label associated with the embedding.\n",
    "        client (Client): The database client used to execute the insert command.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "\n",
    "    Example:\n",
    "        client = get_database_client()\n",
    "        save_embedding(embedding, \"sample_title\", client)\n",
    "\n",
    "    Note:\n",
    "        - A unique identifier (UUID) is generated for each embedding entry.\n",
    "        - The embedding is converted to a list before being saved to the database.\n",
    "        - The client must have a method `command` that executes SQL commands.\n",
    "\n",
    "    Raises:\n",
    "        Any exceptions raised by the `client.command` method will propagate to the caller.\n",
    "    \"\"\"\n",
    "    id = uuid.uuid4()\n",
    "    client.command('INSERT INTO `embedding` (`id`, `vector`, `title`) VALUES (%s, %s, %s)', (id, embedding.tolist(), title))\n",
    "    "
   ],
   "id": "ebaf0b70f1cbf5a1",
   "outputs": [],
   "execution_count": 177
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T17:20:39.177866Z",
     "start_time": "2024-06-09T17:20:39.173100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def search(embedding: np.array, top_k: int, client: Client) -> Sequence[Sequence]:\n",
    "    \"\"\"\n",
    "    Searches for the top-k most similar embeddings in the database based on cosine similarity.\n",
    "\n",
    "    Args:\n",
    "        embedding (np.array): The query embedding to search for, represented as a NumPy array.\n",
    "        top_k (int): The number of top similar embeddings to return.\n",
    "        client (Client): The database client used to execute the search query.\n",
    "\n",
    "    Returns:\n",
    "        Sequence[Sequence]: A sequence of results, where each result is a sequence containing the ID, title, \n",
    "                            and cosine similarity of the matching embeddings.\n",
    "\n",
    "    Example:\n",
    "        client = get_database_client()\n",
    "        results = search(query_embedding, top_k=5, client=client)\n",
    "        for result in results:\n",
    "            print(result)\n",
    "\n",
    "    Note:\n",
    "        - The query is constructed using the embedding converted to a list.\n",
    "        - The cosine similarity is calculated to determine the similarity between embeddings.\n",
    "        - The client must have a method `query` that executes the search query.\n",
    "\n",
    "    Raises:\n",
    "        Any exceptions raised by the `client.query` method will propagate to the caller.\n",
    "    \"\"\"\n",
    "    query = f'''\n",
    "    WITH {embedding.tolist()} as query_vector\n",
    "    SELECT id, title, \n",
    "    arraySum(x -> x * x, vector) * arraySum(x -> x * x, query_vector) != 0\n",
    "    ? arraySum((x, y) -> x * y, vector, query_vector) / sqrt(arraySum(x -> x * x, vector) * arraySum(x -> x * x, query_vector))\n",
    "    : 0 AS cosine_distance\n",
    "    FROM embedding\n",
    "    WHERE length(query_vector) == length(vector)\n",
    "    ORDER BY cosine_distance DESC \n",
    "    LIMIT {top_k}\n",
    "    '''\n",
    "    \n",
    "    result = client.query(query, settings={\"max_query_size\": \"10000000000000\"})\n",
    "    return result.result_rows"
   ],
   "id": "dff9c7a5cba22ca1",
   "outputs": [],
   "execution_count": 189
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Initialize Wav2Vec2 Processor and Model\n",
    "\n",
    "Initialize the Wav2Vec2Processor and Wav2Vec2Model using pre-trained models from Facebook."
   ],
   "id": "cdd2949952f7ee1b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T11:49:24.914210Z",
     "start_time": "2024-06-09T11:49:23.499079Z"
    }
   },
   "cell_type": "code",
   "source": [
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "model = Wav2Vec2Model.from_pretrained(\"facebook/wav2vec2-base-960h\")"
   ],
   "id": "fde9cbc077054071",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/wav2vec2-base-960h were not used when initializing Wav2Vec2Model: ['lm_head.bias', 'lm_head.weight']\n",
      "- This IS expected if you are initializing Wav2Vec2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Connect to ClickHouse\n",
    "\n",
    "Connect to a ClickHouse database client running on localhost at port 8123."
   ],
   "id": "f2d43731a18e1409"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T11:49:37.490088Z",
     "start_time": "2024-06-09T11:49:37.479614Z"
    }
   },
   "cell_type": "code",
   "source": "client = clickhouse_connect.get_client(host='localhost', port=8123)",
   "id": "6ead95b30c0cbbd",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## List Files in Dataset Directory\n",
    "\n",
    "List all files in the \"dataset\" directory."
   ],
   "id": "a89d2d95b541790a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T16:45:53.372231Z",
     "start_time": "2024-06-09T16:45:53.340648Z"
    }
   },
   "cell_type": "code",
   "source": [
    "files = os.listdir(\"dataset\")\n",
    "files"
   ],
   "id": "c90bcb92ec8be3f0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['posledina_lubov.mp3', 'den-h.mp3', 'test.mp3', 'cvetok.mp3']"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 146
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Save Embeddings for Each File\n",
    "\n",
    "Loop through each file in the dataset directory, split it into chunks, compute embeddings, normalize them, and save the embeddings to ClickHouse."
   ],
   "id": "d6752c79374d3711"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T17:06:00.947419Z",
     "start_time": "2024-06-09T17:04:48.467936Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for file in files:\n",
    "    logger.debug(f\"starts saving the file {file}\")\n",
    "    path = os.path.join(\"dataset\", file)\n",
    "    for index, chunk in enumerate(split_on_chunk(path)):\n",
    "        embedding = get_embedding(chunk, processor, model)\n",
    "        embedding = embedding.squeeze().flatten().numpy()\n",
    "        embedding = normalize(embedding)\n",
    "        save_embedding(embedding, file, client)"
   ],
   "id": "c4fc7739dd12e061",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2024-06-09 20:04:48.469\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m2\u001B[0m - \u001B[34m\u001B[1mstarts saving the file posledina_lubov.mp3\u001B[0m\n",
      "\u001B[32m2024-06-09 20:05:05.563\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m2\u001B[0m - \u001B[34m\u001B[1mstarts saving the file den-h.mp3\u001B[0m\n",
      "\u001B[32m2024-06-09 20:05:23.414\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m2\u001B[0m - \u001B[34m\u001B[1mstarts saving the file test.mp3\u001B[0m\n",
      "\u001B[32m2024-06-09 20:05:38.877\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m2\u001B[0m - \u001B[34m\u001B[1mstarts saving the file cvetok.mp3\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 180
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Search Embeddings\n",
    "\n",
    "For a given test file, split it into chunks, compute embeddings, and search for the top 2 nearest embeddings in the database."
   ],
   "id": "8ead0701e99a9400"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-09T17:20:59.355111Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for chunk in split_on_chunk(\"dataset/test.mp3\", chunk_size=2024):\n",
    "    embedding = get_embedding(chunk, processor, model)\n",
    "    embedding = embedding.squeeze().flatten().numpy()\n",
    "    searched = search(embedding , 2, client)\n",
    "    print(searched[0])\n"
   ],
   "id": "d05aa65ecb767a70",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T16:34:59.168994Z",
     "start_time": "2024-06-09T16:34:59.165665Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "d1f393cf77abc41e",
   "outputs": [],
   "execution_count": 140
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "672c460ef63c3921"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
